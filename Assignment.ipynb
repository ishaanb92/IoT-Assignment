{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internet of Things (2IMN25)\n",
    "### Machine Learning Assignment\n",
    "\n",
    "### Introduction\n",
    "\n",
    "*Add assignment description here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import all libraries here \"\"\"\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from dateutil import parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset\n",
    "\n",
    "In the code box below, please read in the data-sets into suitable data structures. The key task here would be to contruct the feature vectors which would be fed to the regression algorithm.\n",
    "\n",
    "The datasets for the weather, rain and energy consumption have been provided in the zip file, extract this zip file into the same folder as the python notebook. \n",
    "\n",
    "*Hint : Be sure to check if there are any missing fields in the provided data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43844, 2)\n",
      "(43872,)\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n",
      "Did not find matching timestamp in the weather data, continuing\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(),'data')\n",
    "\n",
    "\"\"\" Read in the weather\"\"\"\n",
    "weather_array = pd.read_csv(os.path.join(data_path,'Weather-Eindhoven.csv'),\n",
    "                         delimiter = ',',\n",
    "                         header=0,\n",
    "                         parse_dates = [0],\n",
    "                         usecols = [0,2,4,6,7,8]) #Drop \"chill\", too many missing values\n",
    "weather_array  = weather_array.as_matrix()\n",
    "\n",
    "\"\"\" Read in the rain data\"\"\"\n",
    "rain_array = pd.read_csv(os.path.join(data_path,'Rain-Best.csv'),\n",
    "                         delimiter = ',',\n",
    "                         header=0,\n",
    "                         parse_dates = [0])\n",
    "\n",
    "rain_array = rain_array.as_matrix()\n",
    "\n",
    "\"\"\" Synchronize the 2 data-sets by removing the extra data from the rainfall dataset\"\"\"\n",
    "remove_rows = []\n",
    "for element,idx in zip(rain_array[:,0],range(len(rain_array[:,0]))):\n",
    "    if element.minute%10 != 0:\n",
    "        remove_rows.append(idx)\n",
    "\n",
    "synced_rain_array = np.delete(rain_array,remove_rows,axis = 0)\n",
    "\n",
    "print(synced_rain_array.shape)\n",
    "print(weather_array[:,0].shape)\n",
    "\n",
    "\"\"\" Merge the weather and rain data when time-stamps are equal \"\"\"\n",
    "merged_array = []\n",
    "for rainElem in synced_rain_array:\n",
    "    try :\n",
    "        merged_row = []\n",
    "        valid_row = list(weather_array[:,0]).index(rainElem[0])\n",
    "        for weatherFeature in weather_array[valid_row]:\n",
    "            merged_row.append(weatherFeature)\n",
    "        merged_row.append(rainElem[1])\n",
    "        merged_array.append(np.asarray(merged_row))\n",
    "    except ValueError:\n",
    "        print('Did not find matching timestamp in the weather data, continuing')\n",
    "        continue\n",
    "\n",
    "merged_array = np.asarray(merged_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43501, 7)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Clean up the data by removing rows with missing data points \"\"\"\n",
    "missing_data_rows = []\n",
    "for row,idx in zip(merged_array,range(merged_array.shape[0])):\n",
    "    if row[0].month > 10:\n",
    "        missing_data_rows.append(idx)\n",
    "        continue # No energy data for the month of November so delete those too.\n",
    "    for elem in row[1:]: #Timestamp cannot be \"checked\"\n",
    "        if math.isnan(elem):\n",
    "            missing_data_rows.append(idx)\n",
    "            break # To prevent the same row from being added multiple times to the list, break when the first \"nan\" is found\n",
    "clean_data_array = np.delete(merged_array,missing_data_rows,axis=0)\n",
    "print(clean_data_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe(energyDir):\n",
    "    \"\"\" Returns a dataframe that is formed by concatenating all the energy data files \"\"\"\n",
    "    fileList = []\n",
    "    energyDir = os.path.join(os.getcwd(),energyDir)\n",
    "    dirList = [os.path.join(energyDir, o) for o in os.listdir(energyDir) \n",
    "                    if os.path.isdir(os.path.join(energyDir,o))]\n",
    "    \n",
    "    sortedDirList = sorted(dirList)\n",
    "    for direc in sortedDirList:\n",
    "        dirFiles = [os.path.join(direc, f) for f in os.listdir(direc) \n",
    "                    if os.path.isfile(os.path.join(direc,f))]\n",
    "        for f in dirFiles:\n",
    "            fileList.append(f)\n",
    "        \n",
    "    fileList = sorted(fileList)\n",
    "    frame = pd.DataFrame()\n",
    "    frameList = []\n",
    "    for f in fileList:\n",
    "        try:\n",
    "            df = pd.read_csv(f,index_col=None, header=None,parse_dates=[[0,1]])\n",
    "            frameList.append(df)\n",
    "        except:\n",
    "            continue\n",
    "    frame = pd.concat(frameList)\n",
    "    sparseFrame = frame.drop([2,3,4,5,6,7,8,9,12,13],axis=1)\n",
    "    sparseFrame.columns = ['TimeStamp','Energy Consumed','Energy Produced']\n",
    "    badRows = []\n",
    "    # There are some spurious time-stamps like 24:xx:xx which give exceptions when accessed. Remove those rows \n",
    "    for (element,idx) in zip(sparseFrame['TimeStamp'],range(sparseFrame.shape[0])):\n",
    "        try :\n",
    "            dummy=element.hour\n",
    "        except:\n",
    "            badRows.append(idx)\n",
    "\n",
    "    sparseFrame.drop(badRows,axis=0,inplace=True)\n",
    "\n",
    "    return sparseFrame\n",
    "    \n",
    "energyFrame = create_dataframe('data/2017')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
